{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Wrangle Report  \n",
    "\n",
    "On this document i will explain the wrangle effort of this work, the actions and the results.\n",
    "\n",
    "\n",
    "Context\n",
    "Create a 300-600 word written report called wrangle_report.pdf or wrangle_report.html that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "\n",
    "**\"Twitter_archive_enhanced.csv\"**\n",
    "This was the easiest to import, just download the csv file and bring to a dataframe format by .read_csv() Method. This is the classic method to bring a csv file to a dataframe format\n",
    "\n",
    "**image_predictions.tsv**\n",
    "About the second one, i used the requests.get for download and read it the same .read_csv method. Since the data was stored by Udacity Servers, i have to did this function and method to bring possible read on pandas csv read method.\n",
    "\n",
    "**Tweepy API Data**\n",
    "This dataset was the hardest one, because it was necessary a for loop to loop over every id element of the first dataset and bring other informations together. This was a little stressfull, due to Twitter Time to acess the API, it's about 30 minutes for me execute the code for extracting data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing Data\n",
    "\n",
    "### Quality Problems\n",
    "\n",
    "\n",
    "The problems i found on data about Completeness, Validity, Accuracy and Consistency dimensions.\n",
    "\n",
    "The **methods** i use to found these issues were:\n",
    "\n",
    "- .info()\n",
    "- .describe()\n",
    "- .Value_counts()\n",
    "- .duplicated()\n",
    "- .isnull()\n",
    "- .shape()\n",
    "\n",
    "### **DF1**\n",
    "\n",
    "  **Missing Values**\n",
    "\n",
    "in_reply_to_status_id\n",
    "\n",
    "in_reply_to_user_id\n",
    "\n",
    "expanded_urls\n",
    "\n",
    "**Wrong Tiype**\n",
    "\n",
    "Timestamp has a wrong type\n",
    "\n",
    "Tweet_id is wrong too\n",
    "\n",
    "**Wrong values**\n",
    "rating_numerator and rating_denominator has strange values like, they have 0 and 1776 and 170\n",
    "\n",
    "Name columns has a lot of strange names, like 'a' and 'an'\n",
    "\n",
    "\n",
    "**Wrong Data**\n",
    "\n",
    "visually got the doggo, floofer, pupper, and puppo has none in the values.\n",
    "\n",
    "\n",
    "### **DF2**\n",
    "\n",
    "**Missing rows**\n",
    "\n",
    "Here we found only 2075 rows, since the number of rows on the first data frame is 2356.\n",
    "\n",
    "**Wrong Datatype**\n",
    "\n",
    "Tweet_id is int64 instead of a String.\n",
    "\n",
    "\n",
    "### df3 - Tweepy API Data\n",
    "\n",
    "**Wrong Datatype**\n",
    "\n",
    "Tweet_id has a wrong datatype\n",
    "\n",
    "**Wrong Column Names**\n",
    "\n",
    "Id and Gathering_at has wrong column names \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Tidiness Issues\n",
    "\n",
    "The problems about the data structure i found on this dataset\n",
    "\n",
    "### DF1\n",
    "Retweet collums must be deleted\n",
    "The Stage of dog must be on the same collumn\n",
    "\n",
    "### DF2\n",
    "Df2 Must be joined to df 1\n",
    "\n",
    "### DF3\n",
    "df3 must be joined to df 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "For Cleaninig the data, i selected 2 tidiness issues and 8 quality issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tidiness Issues\n",
    "\n",
    "For the Tidiness Issues, obviously i chooose the merging action for the three datasets, since it is one of the tasks of the project 4. For this action i used the **pd.merge** function. \n",
    "\n",
    "And the other Tidiness issue is the stage dog on multiple collumns, i merging the four collumns into one by using .loc to select and fillna to fill the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues\n",
    "\n",
    "Before did the tidiness issues cleaning, i had to change the name collumns \"id\" and \"Created_at\" from the API datasets. After it was cleanned, it was possibile to merging the three datasets, because, now, they have the the same name of ID collumn: \"Tweet_id\"\n",
    "\n",
    "The second quality issue to cleanning was remove RT Rows. For did that i've took the index of not null values from retweeted_status_id.\n",
    "\n",
    "\n",
    "\n",
    "The fourth quality issue to cleanning was timestamp datatype. Since timestamp is a time feature, its type can't be object. The change was to a datetime using **.to_datetime** method.\n",
    "\n",
    "The fifth change was simple. To means of user interface and easy understand, i change the name of timestamp collumn using rename method. Note: This name was created on the merging process \n",
    "\n",
    "The six was a change of datatype too. This time, i changed the tweet_id type to a string datatype. The method i used was **.astype()**.\n",
    "\n",
    "The seventh was a creation of a new collumn facilitating see the true and decimal rate value. For this new feature it was a simple math operation: df_merge2['rating_numerator'] / df_merge2['rating_denominator']\n",
    "\n",
    "The Eight and last cleaning operation was to change dog not names to none values. i dd this by str.match method together with a regex operation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
